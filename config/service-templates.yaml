# Service Type Templates
# Define the contract/schema for each service category in cloud and local modes
#
# Templates are inherited by service instances and define:
# - Required configuration fields
# - Optional configuration fields
# - Docker requirements for local mode
# - Health check patterns

templates:
  # Memory Service Template
  memory:
    description: "Memory and knowledge storage services"
    cloud:
      config_schema:
        - key: api_key
          type: secret
          label: "API Key"
          required: true
        - key: server_url
          type: url
          label: "Server URL"
          required: true
        - key: collection_id
          type: string
          label: "Collection/Namespace ID"
          required: false
      connection:
        health_endpoint: "/health"
        timeout: 30

    local:
      config_schema:
        - key: openai_api_key
          type: secret
          label: "OpenAI API Key"
          description: "Required for OpenMemory's embedding and memory extraction"
          link: "https://platform.openai.com/api-keys"
          required: true
          env_var: OPENAI_API_KEY
          settings_path: "api_keys.openai_api_key"
        - key: server_url
          type: url
          label: "Server URL"
          required: false  # Auto-configured from docker
          default: "http://localhost:8765"
        - key: enable_graph
          type: boolean
          label: "Enable Graph Memory"
          description: "Use Neo4j for relationship tracking"
          default: false
        - key: neo4j_password
          type: secret
          label: "Neo4j Password"
          required: false  # Only if enable_graph=true
          min_length: 8
      docker:
        required: true
        default_port: 8765
        health_endpoint: "/health"
      dependencies:
        - neo4j  # Optional, only if enable_graph=true

  # LLM Service Template
  llm:
    description: "Large Language Model providers"
    cloud:
      config_schema:
        - key: api_key
          type: secret
          label: "API Key"
          description: "API key from your LLM provider"
          link: "https://platform.openai.com/api-keys"  # Default, can be overridden per service
          env_var: "OPENAI_API_KEY"  # Shared credential
          required: true
        - key: base_url
          type: url
          label: "Base URL"
          description: "API endpoint URL"
          required: false  # Provider-specific default
        - key: model
          type: string
          label: "Model"
          description: "Model identifier to use"
          required: false  # Provider-specific default
        - key: temperature
          type: number
          label: "Temperature"
          description: "Sampling temperature (0-2). Higher = more creative, lower = more focused"
          default: 0.7
          min: 0
          max: 2
      connection:
        timeout: 60

    local:
      config_schema:
        - key: base_url
          type: url
          label: "Server URL"
          required: false
          default: "http://localhost:11434"
        - key: model
          type: string
          label: "Model Name"
          description: "Model to use (must be pulled first)"
          required: true
        - key: embedder_model
          type: string
          label: "Embedder Model"
          description: "Model for embeddings"
          required: false
      docker:
        required: true
        default_port: 11434
        health_endpoint: "/api/tags"
        gpu_support: true  # Can use GPU acceleration

  # Transcription Service Template
  transcription:
    description: "Speech-to-text transcription services"
    cloud:
      config_schema:
        - key: api_key
          type: secret
          label: "API Key"
          description: "API key for speech transcription service"
          link: "https://console.deepgram.com/"  # Goes to dashboard/keys page
          env_var: "DEEPGRAM_API_KEY"  # Shared credential
          required: true
        - key: language
          type: string
          label: "Language"
          description: "Target language code (e.g., en, es, fr)"
          default: "en"
        - key: model
          type: string
          label: "Model"
          description: "Transcription model to use"
          required: false
      connection:
        timeout: 120  # Longer timeout for audio processing

    local:
      config_schema:
        - key: server_url
          type: url
          label: "Server URL"
          required: false
          default: "http://localhost:9000"
        - key: model_size
          type: string
          label: "Model Size"
          description: "Larger = more accurate but slower"
          default: "base"
          options: ["tiny", "base", "small", "medium", "large"]
        - key: language
          type: string
          label: "Language"
          default: "en"
      docker:
        required: true
        default_port: 9000
        gpu_support: true
        health_endpoint: "/health"

  # Speaker Recognition Template
  speaker_recognition:
    description: "Speaker identification and diarization"
    cloud:
      config_schema:
        - key: api_key
          type: secret
          label: "API Key"
          required: true
        - key: endpoint_url
          type: url
          label: "Endpoint URL"
          required: true
      connection:
        timeout: 60

    local:
      config_schema:
        - key: server_url
          type: url
          label: "Server URL"
          required: false
          default: "http://localhost:8080"
        - key: similarity_threshold
          type: number
          label: "Similarity Threshold"
          description: "Speaker matching threshold (0-1)"
          default: 0.75
          min: 0
          max: 1
      docker:
        required: true
        default_port: 8080
        health_endpoint: "/health"

  # Conversation Engine Template (Chronicle)
  conversation_engine:
    description: "AI-powered conversation processing with transcription and analysis"
    local:
      config_schema:
        - key: openai_api_key
          type: secret
          label: "OpenAI API Key"
          description: "Required for LLM-based conversation analysis"
          link: "https://platform.openai.com/api-keys"
          required: true
          env_var: OPENAI_API_KEY
          settings_path: "api_keys.openai_api_key"
        - key: deepgram_api_key
          type: secret
          label: "Deepgram API Key"
          description: "Required for speech-to-text transcription"
          link: "https://console.deepgram.com/project/default/keys"
          required: true
          env_var: DEEPGRAM_API_KEY
          settings_path: "api_keys.deepgram_api_key"
        - key: server_url
          type: url
          label: "Server URL"
          required: false
          default: "http://localhost:8080"
        - key: transcription_provider
          type: string
          label: "Transcription Provider"
          description: "Which provider to use for transcription"
          default: "deepgram"
          options: ["deepgram", "mistral"]
        - key: llm_provider
          type: string
          label: "LLM Provider"
          description: "Which LLM to use for analysis"
          default: "openai"
          options: ["openai", "anthropic"]
      docker:
        required: true
        default_port: 8080
        health_endpoint: "/readiness"
      dependencies:
        - mongodb
        - redis
        - qdrant
