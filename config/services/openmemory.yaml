# OpenMemory Service Definition
# Graph-based memory with MCP support
#
# Note: OpenMemory is both a SERVICE (can be deployed) and a PROVIDER
# (implements the memory capability for other services like Chronicle)

id: openmemory
name: "OpenMemory"
description: "Graph-based memory with MCP support and optional Neo4j backend"
version: ">=1.0.0"

# =============================================================================
# CAPABILITIES THIS SERVICE USES
# =============================================================================
# OpenMemory needs an LLM for embeddings and memory extraction

uses:
  - capability: llm
    required: true
    purpose: "Embeddings and memory extraction"
    # No env_mapping for api_key/base_url - OpenMemory uses OpenAI SDK natively
    # Only map OPENAI_MODEL to EMBEDDING_MODEL since OpenMemory uses different env var name
    env_mapping:
      OPENAI_MODEL: EMBEDDING_MODEL

# =============================================================================
# DOCKER CONFIGURATION
# =============================================================================
docker:
  image: ghcr.io/ushadow-io/u-mem0-api:latest
  compose_file: compose/openmemory-compose.yaml
  service_name: mem0

  ports:
    - container: 8765
      host: 8765
      protocol: http

  health:
    http_get: /health
    port: 8765

  volumes:
    - name: mem0-data
      path: /app/data
      persistent: true

# =============================================================================
# INFRASTRUCTURE DEPENDENCIES
# =============================================================================
depends_on:
  required:
    - qdrant     # Vector storage

  optional:
    - neo4j      # Graph storage (only if enable_graph=true)

# =============================================================================
# SERVICE-SPECIFIC CONFIGURATION
# =============================================================================
config:
  # Graph memory toggle
  - key: enable_graph
    env_var: ENABLE_GRAPH_MEMORY
    settings_path: service_preferences.openmemory.enable_graph
    type: boolean
    default: false
    label: "Enable Graph Memory"
    description: "Use Neo4j for relationship tracking"

  # Neo4j connection (only used if enable_graph=true)
  - key: neo4j_uri
    env_var: NEO4J_URI
    settings_path: infrastructure.neo4j.uri
    default: "bolt://neo4j:7687"
    required_if: "enable_graph == true"

  - key: neo4j_user
    env_var: NEO4J_USER
    settings_path: infrastructure.neo4j.user
    default: "neo4j"

  - key: neo4j_password
    env_var: NEO4J_PASSWORD
    settings_path: service_preferences.openmemory.neo4j_password
    type: secret
    required_if: "enable_graph == true"
    min_length: 8

  # Qdrant connection
  - key: qdrant_host
    env_var: QDRANT_HOST
    settings_path: infrastructure.qdrant_base_url
    default: "qdrant"

  - key: qdrant_port
    env_var: QDRANT_PORT
    settings_path: infrastructure.qdrant_port
    default: "6333"

# =============================================================================
# UI METADATA
# =============================================================================
ui:
  icon: brain
  category: memory
  is_default: true
  wizard_order: 2
  tags: ["memory", "mcp", "graph", "local"]

  links:
    docs: https://github.com/ushadow-io/openmemory
