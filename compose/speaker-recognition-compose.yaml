# Speaker Recognition Service Definition
# GPU-accelerated speaker diarization and identification using PyAnnote
#
# This is an OPTIONAL service - not installed by default.
# Install via: ushadow services install speaker-recognition
#
# Profiles:
#   --profile cpu  - CPU-only mode (slower, works everywhere)
#   --profile gpu  - GPU acceleration (requires NVIDIA GPU + CUDA)

# =============================================================================
# USHADOW METADATA (ignored by Docker, read by ushadow backend)
# =============================================================================
x-ushadow:
  speaker-recognition:
    description: "Real-time speaker diarization and identification with GPU acceleration"
    requires: []
    optional_providers: [transcription]  # Can use Deepgram for enhanced mode
    tags: ["audio", "speaker-id", "diarization", "gpu"]
  speaker-recognition-webui:
    description: "Web interface for speaker enrollment, annotation, and inference"
    requires: []

services:
  # ==========================================================================
  # Speaker Recognition Backend (CPU Profile)
  # ==========================================================================
  speaker-recognition:
    &base-speaker-service
    profiles: ["cpu"]
    platform: linux/amd64
    build:
      context: ../speaker-recognition
      dockerfile: Dockerfile
      args:
        PYTORCH_CUDA_VERSION: ${PYTORCH_CUDA_VERSION:-cpu}
    image: speaker-recognition:${SPEAKER_REC_VERSION:-latest}
    container_name: ${COMPOSE_PROJECT_NAME:-ushadow}-speaker-recognition
    # No env_file - ushadow passes environment variables directly via compose subprocess
    ports:
      - "${SPEAKER_SERVICE_PORT:-8085}:${SPEAKER_SERVICE_PORT:-8085}"
    volumes:
      - ../speaker-recognition/src:/app/src
      - speaker_model_cache:/models
      - speaker_audio_chunks:/app/audio_chunks
      - speaker_debug:/app/debug
      - speaker_data:/app/data
    environment:
      - HF_HOME=/models
      - HF_TOKEN=${HF_TOKEN:-}
      - SIMILARITY_THRESHOLD=${SIMILARITY_THRESHOLD:-0.15}
      - SPEAKER_SERVICE_HOST=${SPEAKER_SERVICE_HOST:-0.0.0.0}
      - SPEAKER_SERVICE_PORT=${SPEAKER_SERVICE_PORT:-8085}
      - DEEPGRAM_API_KEY=${DEEPGRAM_API_KEY:-}
    networks:
      - infra-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:${SPEAKER_SERVICE_PORT:-8085}/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s  # Model loading takes time

  # ==========================================================================
  # Speaker Recognition Backend (GPU Profile)
  # Uses pre-built image from ghcr.io with CUDA support
  # ==========================================================================
  speaker-recognition-gpu:
    profiles: ["gpu"]
    platform: linux/amd64
    image: ghcr.io/0xrushi/speaker-recognition:sha-65ddb49
    container_name: ${COMPOSE_PROJECT_NAME:-ushadow}-speaker-recognition-gpu
    ports:
      - "${SPEAKER_SERVICE_PORT:-8085}:${SPEAKER_SERVICE_PORT:-8085}"
    volumes:
      - ../speaker-recognition/src:/app/src
      - speaker_model_cache:/models
      - speaker_audio_chunks:/app/audio_chunks
      - speaker_debug:/app/debug
      - speaker_data:/app/data
    environment:
      - HF_HOME=/models
      - HF_TOKEN=${HF_TOKEN:-}
      - SIMILARITY_THRESHOLD=${SIMILARITY_THRESHOLD:-0.15}
      - SPEAKER_SERVICE_HOST=${SPEAKER_SERVICE_HOST:-0.0.0.0}
      - SPEAKER_SERVICE_PORT=${SPEAKER_SERVICE_PORT:-8085}
      - DEEPGRAM_API_KEY=${DEEPGRAM_API_KEY:-}
    networks:
      default:
        aliases:
          - speaker-recognition
      infra-network:
        aliases:
          - speaker-recognition
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:${SPEAKER_SERVICE_PORT:-8085}/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  # ==========================================================================
  # Speaker Recognition Web UI
  # ==========================================================================
  speaker-recognition-webui:
    profiles: ["cpu", "gpu"]
    platform: linux/amd64
    build:
      context: ../speaker-recognition/webui
      dockerfile: Dockerfile
    image: speaker-recognition-webui:${SPEAKER_REC_VERSION:-latest}
    container_name: ${COMPOSE_PROJECT_NAME:-ushadow}-speaker-webui
    ports:
      - "${SPEAKER_WEBUI_PORT:-5174}:${SPEAKER_WEBUI_PORT:-5174}"
    volumes:
      - ../speaker-recognition/webui/src:/app/src
      - ../speaker-recognition/webui/public:/app/public
    environment:
      - REACT_UI_HOST=${REACT_UI_HOST:-0.0.0.0}
      - REACT_UI_PORT=${SPEAKER_WEBUI_PORT:-5174}
      - REACT_UI_HTTPS=${REACT_UI_HTTPS:-false}
      - SPEAKER_SERVICE_HOST=speaker-recognition
      - SPEAKER_SERVICE_PORT=${SPEAKER_SERVICE_PORT:-8085}
      - VITE_SPEAKER_SERVICE_URL=http://localhost:${SPEAKER_SERVICE_PORT:-8085}
    networks:
      - infra-network
    # Note: No depends_on - both cpu and gpu services use 'speaker-recognition' network alias
    # The webui connects by alias and handles connection retries gracefully
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "/app/healthcheck.sh"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ==========================================================================
  # Nginx Reverse Proxy (HTTPS for microphone access)
  # ==========================================================================
  speaker-nginx:
    image: nginx:alpine
    profiles: ["https"]  # Only needed for HTTPS/microphone access
    container_name: ${COMPOSE_PROJECT_NAME:-ushadow}-speaker-nginx
    ports:
      - "${SPEAKER_HTTPS_PORT:-8444}:443"
      - "${SPEAKER_HTTP_PORT:-8081}:80"
    volumes:
      - ../speaker-recognition/nginx.conf:/etc/nginx/nginx.conf:ro
      - ../speaker-recognition/ssl:/etc/nginx/ssl:ro
    depends_on:
      - speaker-recognition-webui
    networks:
      - infra-network
    restart: unless-stopped

# =============================================================================
# Volumes for data persistence
# =============================================================================
volumes:
  speaker_model_cache:
    driver: local
  speaker_audio_chunks:
    driver: local
  speaker_debug:
    driver: local
  speaker_data:
    driver: local

# =============================================================================
# Networks
# =============================================================================
networks:
  infra-network:
    name: infra-network
    external: true
